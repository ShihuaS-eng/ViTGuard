{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88f1e7d-6090-4d35-8849-ab81a4f19b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import TransformerConfigs_pretrain as configs\n",
    "from TransformerModels_pretrain import ViTModel_custom, ViTForImageClassification\n",
    "\n",
    "sys.path.append('../../')\n",
    "from load_data import load_tiny, GetCIFAR100Validation, GetCIFAR10Validation\n",
    "from Evaluations import test_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35de971a-13c3-45a0-887a-32b658fd88fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA A100-PCIE-40GB)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251eaebe-c87b-43a1-8a56-2a0b34609089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ViTForImageClassification(\n",
       "    (vit): ViTModel_custom(\n",
       "      (embeddings): ViTEmbeddings(\n",
       "        (patch_embeddings): ViTPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): ViTEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x ViTLayer(\n",
       "            (attention): ViTAttention(\n",
       "              (attention): ViTSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): ViTSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): ViTIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): ViTOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (pooler): ViTPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset and model weights\n",
    "dataset = 'TinyImagenet'\n",
    "num_labels = 200\n",
    "model_arch = 'ViT-16'\n",
    "config = configs.get_b16_config()\n",
    "test_loader = load_tiny()\n",
    "model = ViTModel_custom(config=config)\n",
    "model = ViTForImageClassification(config, model, num_labels)\n",
    "filename = \"../results/{}/{}/weights.pth\".format(model_arch, dataset)\n",
    "model.load_state_dict(torch.load(filename), strict=False)\n",
    "model = nn.DataParallel(model).cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d6df4-77ca-4643-a8da-ad5832a83cea",
   "metadata": {},
   "source": [
    "## No attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a052bb1d-bce2-41d5-9234-79c55b729b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.64\n",
      "Test accuracy: 85.03%\n"
     ]
    }
   ],
   "source": [
    "_, adv_acc = test_vit(model=model, test_loader=test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc73ed-4150-4d5f-8e9c-5d0ce6d67ba2",
   "metadata": {},
   "source": [
    "## PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d6860cc-ecfb-4a94-9536-0ec5a32bfd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 11.27\n",
      "Test accuracy: 0.05%\n"
     ]
    }
   ],
   "source": [
    "adv_filepath = \"../results/{}/{}/adv_results/\".format(model_arch, dataset)\n",
    "advLoader = torch.load(adv_filepath+'PGD_advLoader.pth')\n",
    "_, adv_acc = test_vit(model=model, test_loader=advLoader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1edd56-a355-485d-adab-4af9d0652f8b",
   "metadata": {},
   "source": [
    "## CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0917c1a6-0531-4007-84f4-57c871ad4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 12.28\n",
      "Test accuracy: 0.10%\n"
     ]
    }
   ],
   "source": [
    "advLoader = torch.load(adv_filepath+'CW_advLoader.pth')\n",
    "_, adv_acc = test_vit(model=model, test_loader=advLoader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74349a-8fcf-4476-88cf-55e2d63f1f6c",
   "metadata": {},
   "source": [
    "## SGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed41299-cd1a-4ff6-a6a3-c966ffe80a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.19\n",
      "Test accuracy: 34.74%\n"
     ]
    }
   ],
   "source": [
    "advLoader = torch.load(adv_filepath+'SGM_advLoader.pth')\n",
    "_, adv_acc = test_vit(model=model, test_loader=advLoader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4406d750-d7ce-4700-a740-f279e393cee1",
   "metadata": {},
   "source": [
    "## PatchFool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113b73dd-dc82-4bc9-9caa-811f1faa4519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.12\n",
      "Test accuracy: 14.55%\n"
     ]
    }
   ],
   "source": [
    "advLoader = torch.load(adv_filepath+'PatchFool_advLoader.pth')\n",
    "_, adv_acc = test_vit(model=model, test_loader=advLoader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92bade4-eb47-4edb-b61d-1bce5ddf7fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
